[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![MIT License][license-shield]][license-url]
[![LinkedIn][linkedin-shield]][linkedin-url]



<!-- PROJECT LOGO -->
<br />
<p align="center">
  
  <h3 align="center">Web Crawler</h3>
  
  <p align="center">
    This is a project for my Information Retrieval & Web Search class.
    <br />
    (Spring 2021)
    <br />
    



<!-- TABLE OF CONTENTS -->
<details open="open">
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#built-with">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>



<!-- ABOUT THE PROJECT -->
## About The Project

If we want to create a search engine then we should make a crawler that visits web pages and crawls the content and saves it in our repository so that later we can use them to index our documents.

We're going to use a python framework called Scrapy to make this crawler.


### Built With


* [Python](https://www.python.org)
* [Scrapy](https://scrapy.org)
* [PyCharm](https://www.jetbrains.com/pycharm)



<!-- GETTING STARTED -->
## Getting Started

To get a local copy up and running follow these simple example steps.

### Prerequisites

* Python compiler, Editor 

* Terminal / cmd

* Git

### Installation

1. Clone the repo
 ```
   git clone https://github.com/benymaxparsa/Web-Crawler.git
 ```
1. Install Scrapy 
  ``` 
  pip install Scrapy
  ```
1. To run crawler for google play
 ```
   scrapy crawl google_play
 ```



<!-- USAGE EXAMPLES -->
## Usage

Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival.

_For more examples, please refer to the [Documentation](https://docs.scrapy.org/en/latest/index.html)_



<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE` for more information.



<!-- CONTACT -->
## Contact

First Name | Last Name | Student Number
--- | --- | ---
[Parsa](https://github.com/benymaxparsa) | [KamaliPour](https://github.com/benymaxparsa) | `97149081`






<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/benymaxparsa/Web-Crawler?style=for-the-badge
[contributors-url]: https://github.com/benymaxparsa/Web-Crawler/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/benymaxparsa/Web-Crawler?style=for-the-badge
[forks-url]: https://github.com/benymaxparsa/Web-Crawler/network/members
[stars-shield]: https://img.shields.io/github/stars/benymaxparsa/Web-Crawler?style=for-the-badge
[stars-url]: https://github.com/benymaxparsa/Web-Crawler/stargazers
[issues-shield]: https://img.shields.io/github/issues/benymaxparsa/Web-Crawler?style=for-the-badge
[issues-url]: https://github.com/benymaxparsa/Web-Crawler/issues
[license-shield]: https://img.shields.io/github/license/benymaxparsa/Web-Crawler?style=for-the-badge
[license-url]: https://github.com/benymaxparsa/Web-Crawler/blob/main/LICENSE.md
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://www.linkedin.com/in/parsakamalipour/
